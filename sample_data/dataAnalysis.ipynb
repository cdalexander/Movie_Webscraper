{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "                                              0.0/250.0 kB ? eta -:--:--\n",
      "     ---------------------                  143.4/250.0 kB 4.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 250.0/250.0 kB 5.1 MB/s eta 0:00:00\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "!{sys.executable} -m pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data \n",
    "train_data = pd.read_csv(\"C:/Users/cdale/OneDrive/Documents/GitHub/Movie_Webscraper/sample_data/train.csv\")\n",
    "train_data.drop_duplicates()\n",
    "columns_to_drop = [\"homepage\", \"overview\", \"poster_path\", \"Keywords\", \"tagline\", \"imdb_id\", \"belongs_to_collection\", \"id\"]\n",
    "train_data = train_data.drop(columns= columns_to_drop)\n",
    "\n",
    "# train_data\n",
    "# Explore the training data\n",
    "# print(train_data.head(20))\n",
    "# print(train_data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling in empty data with null values\n",
    "train_data.replace('', pd.NA, inplace=True)\n",
    "train_data.replace(0, pd.NA, inplace=True)\n",
    "\n",
    "# Dropping duplicate values\n",
    "train_data = train_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dropna(subset=['production_companies', 'production_countries', 'spoken_languages', 'cast', 'crew', 'budget', 'genres', 'original_language', 'popularity', 'release_date', 'runtime', 'status', 'title', 'revenue'  ], inplace=True)\n",
    "\n",
    "# train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulls the 'id' key from the dictionary and replaces that number in the \"id\" column. Then deletes the \"belongs to collection\" column.\n",
    "# train_data['belongs_to_collection'] = train_data['belongs_to_collection'].apply(eval)\n",
    "# train_data['id'] = train_data['belongs_to_collection'].apply(lambda x: x[0]['id'])\n",
    "\n",
    "# Pulls the genre names from the dictionary in the \"genres\" column and add them to a new column \"genre\". Then deletes the \"genres\" column.\n",
    "train_data['genres'] = train_data['genres'].apply(eval)\n",
    "train_data['genre'] = train_data['genres'].apply(lambda x: \", \".join([genre['name'] for genre in x]))\n",
    "train_data = train_data.drop(columns= \"genres\")\n",
    "\n",
    "\n",
    "# Pulls the production company names out of the \"production_companies\" column and places them in the new column \"production_company\". Then deletes the \"prodution_companies\" column.\n",
    "train_data['production_companies'] = train_data['production_companies'].apply(eval)\n",
    "train_data['production_company'] = train_data['production_companies'].apply(lambda x: \", \".join([company['name'] for company in x]))\n",
    "train_data = train_data.drop(columns= \"production_companies\")\n",
    "\n",
    "\n",
    "# Pulls the production country names out of the \"production_countries\" column and places them in the new column \"production_country\". Then deletes the \"prodution_country\" column.\n",
    "train_data['production_countries'] = train_data['production_countries'].apply(eval)\n",
    "train_data['production_country'] = train_data['production_countries'].apply(lambda x: \", \".join([country['name'] for country in x]))\n",
    "train_data = train_data.drop(columns= \"production_countries\")\n",
    "\n",
    "\n",
    "# Pulls the spoken languages out of the \"spoken_languages\" column and places them in the new column \"spoken_language\". Then deletes the \"spoken_language\" column.\n",
    "train_data['spoken_languages'] = train_data['spoken_languages'].apply(eval)\n",
    "train_data['spoken_language'] = train_data['spoken_languages'].apply(lambda x: \", \".join([language['name'] for language in x]))\n",
    "train_data = train_data.drop(columns= \"spoken_languages\")\n",
    "\n",
    "\n",
    "\n",
    "# Isolates the \"character\" and \"name\"(actor) keys from the \"cast\" column and puts them in the new column \"cast_info\"\n",
    "train_data['cast'] = train_data['cast'].apply(eval)\n",
    "train_data['cast_info'] = train_data['cast'].apply(lambda x: [{'character': actor['character'], 'name': actor['name']} for actor in x] if isinstance(x, list) else [])\n",
    "train_data = train_data.drop(columns='cast')\n",
    "train_data['actors'] = train_data['cast_info'].apply(lambda x: \", \".join([actor['name'] for actor in x]))\n",
    "train_data = train_data.drop(columns='cast_info')\n",
    "\n",
    "\n",
    "#Isolates the 'job' and 'name' key in the crew column\n",
    "train_data['crew'] = train_data['crew'].apply(eval)\n",
    "def extract_director_name(crews):\n",
    "    for crew in crews:\n",
    "        if 'job' in crew and crew['job'] == \"Director\" and 'name' in crew:\n",
    "            return crew['name']\n",
    "    return 0\n",
    "    \n",
    "train_data['director'] = train_data['crew'].apply(extract_director_name)\n",
    "\n",
    "train_data = train_data.drop(columns='crew')\n",
    "\n",
    "train_data.replace('', pd.NA, inplace=True)\n",
    "train_data.replace(0, pd.NA, inplace=True)\n",
    "\n",
    "\n",
    "train_data.dropna(subset=['genre', 'production_company', 'production_country', 'spoken_language', 'actors', 'director' ], inplace=True)\n",
    "\n",
    "\n",
    "# train_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_file = \"TrainData.xlsx\"\n",
    "\n",
    "# train_data.to_excel(train_data_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
